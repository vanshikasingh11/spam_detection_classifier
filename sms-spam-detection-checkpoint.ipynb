{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "246177b0-7ccb-4094-8d33-a986cdc905ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a8257365-d3fa-4470-b108-8927b53f08d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('spam.csv', encoding='ISO-8859-1')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c1524eaf-39da-4509-96a4-11a8629a2f4c",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.sample(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d35ec0e4-b45b-4bd5-ba3e-c6523c69313a",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d6163d8a-8640-4837-910d-2bd2f7288134",
   "metadata": {},
   "outputs": [],
   "source": [
    "from wordcloud import WordCloud\n",
    "wc = WordCloud(width=500, height=500, min_font_size=10, background_color='white')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b30e8468-a71c-416e-87ed-a1c4cd2176cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "#1. data cleaning\n",
    "#2.EDA\n",
    "#3.Text Preprocessing\n",
    "#4.Model building\n",
    "#5.Evaluation\n",
    "#6. Improvement\n",
    "#7. Website\n",
    "#8. Deploy"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cd5f675e-302f-402c-bb21-636e27ecad69",
   "metadata": {},
   "source": [
    "## 1. DATA CLEANING"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b968f7f2-278e-43ac-a10c-fea81aa2bfa8",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "51ea6f64-7faf-44c4-9192-3a9cc51afefd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# drop last 3 cols\n",
    "df.drop(columns=['Unnamed: 2', 'Unnamed: 3', 'Unnamed: 4'], inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8271704b-76ea-4df6-b197-d23bfadf5145",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.sample(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aa4ff069-a91c-4746-acf5-9614851b0943",
   "metadata": {},
   "outputs": [],
   "source": [
    "#renaming the cols\n",
    "df.rename(columns={'v1': 'target', 'v2': 'text'}, inplace=True)\n",
    "df.sample(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1f78b635-de26-495b-99ca-9c3dd6e86321",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import LabelEncoder\n",
    "encoder = LabelEncoder()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2dd6fe47-ac21-495c-b241-f94aa284ed72",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['target'] = encoder.fit_transform(df['target'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "39af45b4-2ea1-43bb-85fd-ccdb198f80cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e89fbc3f-9560-49ad-bd4b-38b068694d76",
   "metadata": {},
   "outputs": [],
   "source": [
    "#missing values\n",
    "df.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "365b1344-8f0c-483c-a674-fc3cd47ac6d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "#check for duplicate values\n",
    "df.duplicated().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1c0a2143-9bd3-4043-be14-3b1cc547ed82",
   "metadata": {},
   "outputs": [],
   "source": [
    "#remove duplicates\n",
    "df = df.drop_duplicates(keep='first')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "49258be8-b528-43e2-9e13-99f65c10f9c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.duplicated().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2cf569aa-16f7-4d0f-9018-ef856ad083aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "87471386-fed3-4bd7-aa76-9a7e5ece37fb",
   "metadata": {},
   "source": [
    "# 2. EDA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "49c01110-d2f0-4936-a365-1ce7c07fbe3f",
   "metadata": {},
   "outputs": [],
   "source": [
    " df['target'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2943925d-a8c0-4884-a6e2-51417c1f4b97",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "plt.pie(df['target'].value_counts() , labels = ['ham', 'spam'] , autopct=\"%0.2f\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "525eff43-5a7f-4307-a59e-451f67979dad",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Data is imbalanced"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "569cc87b-6aab-4812-9875-7caf5dfc8810",
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f495e06a-ed6a-4d79-9d66-6830afe79f6b",
   "metadata": {},
   "outputs": [],
   "source": [
    "nltk.download('punkt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8dffa577-3922-4573-9242-cbfb81e31788",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['num_characters'] = df['text'].apply(len)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "29ff8603-8571-44c5-a18b-34eac5d5d900",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d4b1e11c-f818-44c7-b7bf-c79ce8f07779",
   "metadata": {},
   "outputs": [],
   "source": [
    "#num of words\n",
    "df['num_words'] = df['text'].apply(lambda x: len(nltk.word_tokenize(x)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "876b80f5-dc62-488e-a11b-56a38a362322",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eef6e299-769a-4ffe-820d-17c1f6d46956",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['num_sentences']= df['text'].apply(lambda x: len(nltk.sent_tokenize(x)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "508caa29-e407-4c0c-88d0-a426115d1b82",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e8a1c7fa-3ce5-4725-a707-fbfb58ac375c",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "08db9a5c-e151-4182-a554-208ea0012f59",
   "metadata": {},
   "outputs": [],
   "source": [
    "df[['num_characters','num_words','num_sentences']].describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f330effe-57e9-4306-bf7b-0c211fc013be",
   "metadata": {},
   "outputs": [],
   "source": [
    "#ham\n",
    "df[df['target'] == 0][['num_characters','num_words','num_sentences']].describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "43abc396-3809-4622-ac37-1ace4b72aa5f",
   "metadata": {},
   "outputs": [],
   "source": [
    "#spam\n",
    "df[df['target'] == 1][['num_characters','num_words','num_sentences']].describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "00f9c283-7bc3-4331-81f0-7cb0f98f5d03",
   "metadata": {},
   "outputs": [],
   "source": [
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "23dfa018-86d8-415c-8d4f-bfb6991327e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(12,6))\n",
    "sns.histplot(df[df['target'] == 0]['num_characters'])\n",
    "sns.histplot(df[df['target'] == 1]['num_characters'] , color='red')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "632a94db-5c48-42e1-8754-6f946da083c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(12,6))\n",
    "sns.histplot(df[df['target'] == 0]['num_words'])\n",
    "sns.histplot(df[df['target'] == 1]['num_words'] , color='red')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6703f481-8efc-4bd9-82d6-fde5babcefad",
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.pairplot(df, hue='target')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "db1f889d-debe-45df-a872-f211dc5ee81e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Select only numeric columns from the DataFrame\n",
    "numeric_df = df.select_dtypes(include=['float64', 'int64'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bc94a39e-445b-4c7e-b5fd-0284ba82a84a",
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.heatmap(numeric_df.corr(), annot=True, cmap='coolwarm', fmt='.2f')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "848cfe1f-6633-4ccb-849e-8535b933e3cb",
   "metadata": {},
   "source": [
    "**3. DATA PREPROCESSING**\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4949ceca-680b-4ea7-981a-f1b0c6331e8c",
   "metadata": {},
   "outputs": [],
   "source": [
    "#LOWER CASE\n",
    "#TOKENIZATION\n",
    "#REMOVING SPECIAL CHARACTERS\n",
    "#REMOVING STOP WORDS AND PUNCTUATIONS\n",
    "#STEMMING"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "69773290-2e4b-4ddf-8294-2684a1bba371",
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem import PorterStemmer\n",
    "import string\n",
    "\n",
    "# Ensure you have the necessary NLTK resources downloaded\n",
    "nltk.download('stopwords')\n",
    "nltk.download('punkt')\n",
    "\n",
    "def transform_text(text):\n",
    "    # Convert text to lowercase\n",
    "    text = text.lower()\n",
    "    \n",
    "    # Tokenize the text\n",
    "    tokens = nltk.word_tokenize(text)\n",
    "    \n",
    "    # Initialize the PorterStemmer\n",
    "    ps = PorterStemmer()\n",
    "    \n",
    "    # Prepare an empty list for processed tokens\n",
    "    processed_tokens = []\n",
    "    \n",
    "    # Filter out stopwords, punctuation, and stem the words\n",
    "    for token in tokens:\n",
    "        if token.isalnum() and token not in stopwords.words('english'):\n",
    "            stemmed_token = ps.stem(token)\n",
    "            processed_tokens.append(stemmed_token)\n",
    "    \n",
    "    # Join the processed tokens into a single string and return\n",
    "    return \" \".join(processed_tokens)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b9961c66-1864-4b36-b35d-f3422c88c3f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "transform_text('Go until jurong point, crazy.. Available only in bugis n great world la e buffet... Cine there got amore wat...')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2919aa54-ab5f-418b-bb80-3223d56d6330",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['text'][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9bdec746-e979-482b-b425-fedd5bd9cf75",
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.stem.porter import PorterStemmer\n",
    "ps = PorterStemmer()\n",
    "ps.stem('playing')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "201b2176-50aa-43ec-9725-11c58f1580ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['transformed_text'] = df['text'].apply(transform_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "41dfa788-d8d3-4a64-8280-7acab404f51b",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7fdaaf29-006c-4839-9f52-e67433e72186",
   "metadata": {},
   "outputs": [],
   "source": [
    "spam_wc = wc.generate(df[df['target'] == 1 ]['transformed_text'].str.cat(sep = \" \"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3dc71473-1fdf-46b4-b2cd-eb72c454c65a",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.imshow(spam_wc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a7be47df-a8d4-4a76-b280-776d8b069e03",
   "metadata": {},
   "outputs": [],
   "source": [
    "ham_wc = wc.generate(df[df['target'] == 0 ]['transformed_text'].str.cat(sep = \" \"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c5b1063d-d43d-4c59-90f4-de3110cf93cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.imshow(ham_wc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f0ab2d3c-9946-44de-b05a-766f3e0d748d",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b0c0715b-8f81-4179-910c-9e32e0c04337",
   "metadata": {},
   "outputs": [],
   "source": [
    "spam_corpus = []\n",
    "for msg in df[df['target'] == 1]['transformed_text'].tolist():\n",
    "    for word in msg.split():\n",
    "        spam_corpus.append(word)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "176ba6d6-28ba-4913-ab89-3355da031fb7",
   "metadata": {},
   "outputs": [],
   "source": [
    "len(spam_corpus)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a4edf507-58b5-4162-967a-767030c5da49",
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import Counter\n",
    "# Get the 30 most common words in 'spam_corpus'\n",
    "common_words = pd.DataFrame(Counter(spam_corpus).most_common(30), columns=['word', 'count'])\n",
    "\n",
    "# Create a barplot using Seaborn\n",
    "sns.barplot(x='word', y='count', data=common_words, palette='Set2', hue=None, legend=False)\n",
    "\n",
    "plt.xticks(rotation= 'vertical')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c6c94695-64eb-422e-873b-f5c3e3201d72",
   "metadata": {},
   "outputs": [],
   "source": [
    "ham_corpus = []\n",
    "for msg in df[df['target'] == 0]['transformed_text'].tolist():\n",
    "    for word in msg.split():\n",
    "        ham_corpus.append(word)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "37c3fd0b-9089-47b2-974f-1a823da84308",
   "metadata": {},
   "outputs": [],
   "source": [
    "len(ham_corpus)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8a136c73-5bcd-4b82-ba7b-94a51fdc24d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import Counter\n",
    "# Get the 30 most common words in 'spam_corpus'\n",
    "common_words = pd.DataFrame(Counter(ham_corpus).most_common(30), columns=['word', 'count'])\n",
    "\n",
    "# Create a barplot using Seaborn\n",
    "sns.barplot(x='word', y='count', data=common_words, palette='Set2', hue=None, legend=False)\n",
    "\n",
    "plt.xticks(rotation= 'vertical')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4f069d6e-3f2a-44f1-9c15-4ee27dd96db9",
   "metadata": {},
   "source": [
    "**4. Model Building**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4fdb1979-51c7-45ab-82a2-327e33bc7bb6",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer,TfidfVectorizer\n",
    "cv = CountVectorizer()\n",
    "tfidf = TfidfVectorizer(max_features=3000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bf7214e5-6584-46bd-b2dc-47faea25313e",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = tfidf.fit_transform(df['transformed_text']).toarray()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e3b8099c-a23f-4388-baa4-1db6c7b28668",
   "metadata": {},
   "outputs": [],
   "source": [
    "#from sklearn.preprocessing import MinMaxScaler\n",
    "#scaler = MinMaxScaler()\n",
    "#X = scaler.fit_transform(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c6ab9e23-e4a1-4837-88bf-165f86978a13",
   "metadata": {},
   "outputs": [],
   "source": [
    "# appending the num_character col to X\n",
    "#X = np.hstack((X,df['num_characters'].values.reshape(-1,1)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0776aa35-cbc4-485d-9019-fa7615aac7cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "X.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e44feee8-3abd-45f7-bea3-0e9f7bf61ec9",
   "metadata": {},
   "outputs": [],
   "source": [
    "y = df['target'].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c1676c3f-4126-4ec1-8e1f-86fef1273b35",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0c272900-7c7c-441f-adb2-bd60a91f9596",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train,X_test,y_train,y_test = train_test_split(X,y,test_size=0.2,random_state=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "93ff30d6-c684-4e5a-951d-a4d64bdb772c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.naive_bayes import GaussianNB,MultinomialNB,BernoulliNB\n",
    "from sklearn.metrics import accuracy_score,confusion_matrix,precision_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "654c517e-7036-43ec-b7d5-3cf22706e412",
   "metadata": {},
   "outputs": [],
   "source": [
    "gnb = GaussianNB()\n",
    "mnb = MultinomialNB()\n",
    "bnb = BernoulliNB()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c74142d0-a82c-4815-8f1b-d73e1f4ce78f",
   "metadata": {},
   "outputs": [],
   "source": [
    "gnb.fit(X_train,y_train)\n",
    "y_pred1 = gnb.predict(X_test)\n",
    "print(accuracy_score(y_test,y_pred1))\n",
    "print(confusion_matrix(y_test,y_pred1))\n",
    "print(precision_score(y_test,y_pred1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3089a4d4-33b9-4977-8849-2daa4e336a53",
   "metadata": {},
   "outputs": [],
   "source": [
    "mnb.fit(X_train,y_train)\n",
    "y_pred2 = mnb.predict(X_test)\n",
    "print(accuracy_score(y_test,y_pred2))\n",
    "print(confusion_matrix(y_test,y_pred2))\n",
    "print(precision_score(y_test,y_pred2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b7f18d59-7d2e-48a1-bffd-7d21c735ef31",
   "metadata": {},
   "outputs": [],
   "source": [
    "bnb.fit(X_train,y_train)\n",
    "y_pred3 = bnb.predict(X_test)\n",
    "print(accuracy_score(y_test,y_pred3))\n",
    "print(confusion_matrix(y_test,y_pred3))\n",
    "print(precision_score(y_test,y_pred3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e2893073-a30a-4037-8657-1c8dea7bfc22",
   "metadata": {},
   "outputs": [],
   "source": [
    "# tfidf --> MNB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "defaabc2-611a-462a-8c3a-fdead423a64e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.ensemble import AdaBoostClassifier\n",
    "from sklearn.ensemble import BaggingClassifier\n",
    "from sklearn.ensemble import ExtraTreesClassifier\n",
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "from xgboost import XGBClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9428af05-940f-4761-8f26-a241cb7c0e3f",
   "metadata": {},
   "outputs": [],
   "source": [
    "svc = SVC(kernel='sigmoid', gamma=1.0)\n",
    "knc = KNeighborsClassifier()\n",
    "mnb = MultinomialNB()\n",
    "dtc = DecisionTreeClassifier(max_depth=5)\n",
    "lrc = LogisticRegression(solver='liblinear', penalty='l1')\n",
    "rfc = RandomForestClassifier(n_estimators=50, random_state=2)\n",
    "abc = AdaBoostClassifier(n_estimators=50, random_state=2)\n",
    "bc = BaggingClassifier(n_estimators=50, random_state=2)\n",
    "etc = ExtraTreesClassifier(n_estimators=50, random_state=2)\n",
    "gbdt = GradientBoostingClassifier(n_estimators=50,random_state=2)\n",
    "xgb = XGBClassifier(n_estimators=50,random_state=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "45edd135-93ee-437e-9c95-cd490ee27fa5",
   "metadata": {},
   "outputs": [],
   "source": [
    "clfs = {\n",
    "    'SVC' : svc,\n",
    "    'KN' : knc, \n",
    "    'NB': mnb, \n",
    "    'DT': dtc, \n",
    "    'LR': lrc, \n",
    "    'RF': rfc, \n",
    "    'AdaBoost': abc, \n",
    "    'BgC': bc, \n",
    "    'ETC': etc,\n",
    "    'GBDT':gbdt,\n",
    "    'xgb':xgb\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "49da3233-3dca-461b-ba24-1a7c1a0370d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_classifier(clf,X_train,y_train,X_test,y_test):\n",
    "    clf.fit(X_train,y_train)\n",
    "    y_pred = clf.predict(X_test)\n",
    "    accuracy = accuracy_score(y_test,y_pred)\n",
    "    precision = precision_score(y_test,y_pred)\n",
    "    \n",
    "    return accuracy,precision"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "20d29888-04a5-437e-9d73-24f0528e609c",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_classifier(svc,X_train,y_train,X_test,y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d91adfaa-ebf7-4bbc-91e2-4d1c77abb43b",
   "metadata": {},
   "outputs": [],
   "source": [
    "accuracy_scores = []\n",
    "precision_scores = []\n",
    "\n",
    "for name,clf in clfs.items():\n",
    "    \n",
    "    current_accuracy,current_precision = train_classifier(clf, X_train,y_train,X_test,y_test)\n",
    "    \n",
    "    print(\"For \",name)\n",
    "    print(\"Accuracy - \",current_accuracy)\n",
    "    print(\"Precision - \",current_precision)\n",
    "    \n",
    "    accuracy_scores.append(current_accuracy)\n",
    "    precision_scores.append(current_precision)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a8b6636c-6aa0-4082-8dcd-a643d73d08f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "performance_df = pd.DataFrame({'Algorithm':clfs.keys(),'Accuracy':accuracy_scores,'Precision':precision_scores}).sort_values('Precision',ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "41e11110-2a9a-453c-addc-4264c9552db1",
   "metadata": {},
   "outputs": [],
   "source": [
    "performance_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4b61df26-7bf3-48dc-8c60-fb546f86fede",
   "metadata": {},
   "outputs": [],
   "source": [
    "performance_df1 = pd.melt(performance_df, id_vars = \"Algorithm\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "941878f1-c301-4147-b030-a70b673bcedf",
   "metadata": {},
   "outputs": [],
   "source": [
    "performance_df1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c5d0c3c2-dd1d-4903-9d6a-2cdbbe55542c",
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.catplot(x = 'Algorithm', y='value', \n",
    "               hue = 'variable',data=performance_df1, kind='bar',height=5)\n",
    "plt.ylim(0.5,1.0)\n",
    "plt.xticks(rotation='vertical')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cb1d6632-9f86-4337-96a8-bf128c0fdc49",
   "metadata": {},
   "outputs": [],
   "source": [
    "# model improve\n",
    "# 1. Change the max_features parameter of TfIdf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3e93be24-8f89-4981-8309-136eef1b7b0b",
   "metadata": {},
   "outputs": [],
   "source": [
    "temp_df = pd.DataFrame({'Algorithm':clfs.keys(),'Accuracy_max_ft_3000':accuracy_scores,'Precision_max_ft_3000':precision_scores}).sort_values('Precision_max_ft_3000',ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6871baee-a26a-47ce-b7d6-dc81b8bae28e",
   "metadata": {},
   "outputs": [],
   "source": [
    "temp_df = pd.DataFrame({'Algorithm':clfs.keys(),'Accuracy_scaling':accuracy_scores,'Precision_scaling':precision_scores}).sort_values('Precision_scaling',ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "79c5ca5a-5170-4302-bd55-5e25f1c5efd2",
   "metadata": {},
   "outputs": [],
   "source": [
    "new_df = performance_df.merge(temp_df,on='Algorithm')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2ab6676c-4089-421e-b86f-9fb56d29e722",
   "metadata": {},
   "outputs": [],
   "source": [
    "new_df_scaled = new_df.merge(temp_df,on='Algorithm')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aa4014a9-09b9-4586-8a72-d1a5b422a00d",
   "metadata": {},
   "outputs": [],
   "source": [
    "temp_df = pd.DataFrame({'Algorithm':clfs.keys(),'Accuracy_num_chars':accuracy_scores,'Precision_num_chars':precision_scores}).sort_values('Precision_num_chars',ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ba8427d9-bc7b-45bf-9a2a-c06048035aef",
   "metadata": {},
   "outputs": [],
   "source": [
    "new_df_scaled.merge(temp_df,on='Algorithm')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bb7ed9ec-2d20-4298-af78-a298bd2bef1b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Voting Classifier\n",
    "svc = SVC(kernel='sigmoid', gamma=1.0,probability=True)\n",
    "mnb = MultinomialNB()\n",
    "etc = ExtraTreesClassifier(n_estimators=50, random_state=2)\n",
    "\n",
    "from sklearn.ensemble import VotingClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5c4beaae-f1f2-4ee3-8ee6-25d15f3181e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "voting = VotingClassifier(estimators=[('svm', svc), ('nb', mnb), ('et', etc)],voting='soft')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2cbdf17f-c2b8-4cf7-9048-0a4ea104961a",
   "metadata": {},
   "outputs": [],
   "source": [
    "voting.fit(X_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4c54be67-182a-49e6-b6e5-ad579475a8c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = voting.predict(X_test)\n",
    "print(\"Accuracy\",accuracy_score(y_test,y_pred))\n",
    "print(\"Precision\",precision_score(y_test,y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d9abf0c3-7e75-464e-b437-75286f694b52",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Applying stacking\n",
    "estimators=[('svm', svc), ('nb', mnb), ('et', etc)]\n",
    "final_estimator=RandomForestClassifier()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "33d60c23-289a-424f-8013-4eb081791154",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.ensemble import ExtraTreesClassifier, RandomForestClassifier, StackingClassifier\n",
    "from sklearn.metrics import accuracy_score, precision_score\n",
    "\n",
    "# Sample data\n",
    "X = np.random.rand(100, 5)  # 100 samples, 5 features\n",
    "y = np.random.randint(0, 2, size=100)  # Binary target variable\n",
    "\n",
    "# Split the data into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Define base estimators\n",
    "svc = SVC(probability=True)  # Set probability=True for stacking\n",
    "mnb = MultinomialNB()\n",
    "etc = ExtraTreesClassifier()\n",
    "\n",
    "# Define the stacking classifier\n",
    "estimators = [('svm', svc), ('nb', mnb), ('et', etc)]\n",
    "final_estimator = RandomForestClassifier()\n",
    "clf = StackingClassifier(estimators=estimators, final_estimator=final_estimator)\n",
    "\n",
    "# Fit the stacking classifier\n",
    "clf.fit(X_train, y_train)\n",
    "\n",
    "# Make predictions\n",
    "y_pred = clf.predict(X_test)\n",
    "\n",
    "# Calculate and print accuracy and precision\n",
    "print(\"Accuracy:\", accuracy_score(y_test, y_pred))\n",
    "print(\"Precision:\", precision_score(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7b22167c-b3fd-43be-9a42-4fb02e29f219",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "pickle.dump(tfidf,open('vectorizer.pkl','wb'))\n",
    "pickle.dump(mnb,open('model.pkl','wb'))\n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3fa9935d-55e4-471f-82df-75087a888e84",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.metrics import accuracy_score, confusion_matrix\n",
    "\n",
    "# Sample data\n",
    "X = np.random.rand(100, 5)  # 100 samples, 5 features\n",
    "y = np.random.choice(['ham', 'spam'], size=100)  # Categorical target variable\n",
    "\n",
    "# Encode the target variable\n",
    "label_encoder = LabelEncoder()\n",
    "y_encoded = label_encoder.fit_transform(y)\n",
    "\n",
    "# Split the data into training and testing sets\n",
    "X_train, X_test, y_train_encoded, y_test = train_test_split(X, y_encoded, test_size=0.2, random_state=42)\n",
    "\n",
    "# Create an instance of the MultinomialNB model\n",
    "mnb = MultinomialNB()\n",
    "\n",
    "# Fit the model with training data\n",
    "mnb.fit(X_train, y_train_encoded)\n",
    "\n",
    "# Make predictions on the training set\n",
    "y_train_pred = mnb.predict(X_train)\n",
    "\n",
    "# Print training labels and predictions\n",
    "print(\"Training labels:\", label_encoder.inverse_transform(y_train_encoded))\n",
    "print(\"Training predictions:\", label_encoder.inverse_transform(y_train_pred))\n",
    "\n",
    "# Evaluate on training data\n",
    "train_accuracy = accuracy_score(y_train_encoded, y_train_pred)\n",
    "print(\"Training Accuracy:\", train_accuracy)\n",
    "\n",
    "# Confusion matrix\n",
    "cm = confusion_matrix(y_train_encoded, y_train_pred)\n",
    "print(\"Confusion Matrix:\\n\", cm)\n",
    "\n",
    "# Make predictions on the test set\n",
    "y_pred = mnb.predict(X_test)\n",
    "print(\"Test Predictions:\", label_encoder.inverse_transform(y_pred))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3ba4612b-403f-484b-8fd5-abf0f40f0b1d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Assuming mnb is already fitted and you have defined X_train\n",
    "# Example input for prediction (make sure it has the same number of features as X_train)\n",
    "vector_input = np.array([[0.5, 0.2, 0.1, 0.3, 0.4]])  # Example input with 5 features\n",
    "\n",
    "# Check if the model is fitted and make predictions\n",
    "if hasattr(mnb, 'classes_'):\n",
    "    result = mnb.predict(vector_input)\n",
    "    print(\"Predictions:\", result)\n",
    "else:\n",
    "    print(\"Model is not fitted yet.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c18106a9-8944-4cb1-8032-a7d902e04eeb",
   "metadata": {},
   "outputs": [],
   "source": [
    "def text_clean(text, method, rm_stop):\n",
    "    text = re.sub(r\"\\n\",\"\",text)   #remove line breaks\n",
    "    text = text.lower() #convert to lowercase \n",
    "    text = re.sub(r\"\\d+\",\"\",text)   #remove digits and currencies \n",
    "    text = re.sub(r'[\\$\\d+\\d+\\$]', \"\", text)      \n",
    "    text = re.sub(r'\\d+[\\.\\/-]\\d+[\\.\\/-]\\d+', '', text)   #remove dates \n",
    "    text = re.sub(r'\\d+[\\.\\/-]\\d+[\\.\\/-]\\d+', '', text)\n",
    "    text = re.sub(r'\\d+[\\.\\/-]\\d+[\\.\\/-]\\d+', '', text)\n",
    "    text = re.sub(r'[^\\x00-\\x7f]',r' ',text)   #remove non-ascii\n",
    "    text = re.sub(r'[^\\w\\s]','',text)   #remove punctuation\n",
    "    text = re.sub(r'https?:\\/\\/.*[\\r\\n]*', '', text)   #remove hyperlinks\n",
    "    \n",
    "    #remove stop words \n",
    "    if rm_stop == True:\n",
    "        filtered_tokens = [word for word in word_tokenize(text) if not word in set(stopwords.words('english'))]\n",
    "        text = \" \".join(filtered_tokens)\n",
    "        \n",
    "    #lemmatization: typically preferred over stemming\n",
    "    if method == 'L':\n",
    "        lemmer = WordNetLemmatizer()\n",
    "        lemm_tokens = [lemmer.lemmatize(word) for word in word_tokenize(text)]\n",
    "        return \" \".join(lemm_tokens)\n",
    "    \n",
    "    #stemming \n",
    "    if method == 'S':\n",
    "        porter = PorterStemmer()\n",
    "        stem_tokens = [porter.stem(word) for word in word_tokenize(text)]\n",
    "        return \" \".join(stem_tokens)\n",
    "    \n",
    "    return text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "51e00298-e342-44a7-a338-1c6ccb672750",
   "metadata": {},
   "outputs": [],
   "source": [
    "#preprocessed data: Lemm + stopword removal \n",
    "preprocessed_text_1 = [text_clean(text, 'L', True) for text in X_train]\n",
    "#preprocessed_text_1[0:10]\n",
    "\n",
    "#preprocessed data: Lemm + no stopword removal \n",
    "preprocessed_text_2 = [text_clean(text, 'L', False) for text in X_train]\n",
    "#preprocessed_text_2[0:10]\n",
    "\n",
    "#preprocessed data: Stem + stopword removal \n",
    "preprocessed_text_3 = [text_clean(text, 'S', True) for text in X_train]\n",
    "#preprocessed_text_3[0:10]\n",
    "\n",
    "#preprocessed data: Stem + no stopword removal \n",
    "preprocessed_text_4 = [text_clean(text, 'S', False) for text in X_train]\n",
    "#preprocessed_text_4[0:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "43e228e0-0c33-4a68-84d5-d1a955d34e37",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ed72a026-1f19-413a-b813-5a5fcac68015",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
